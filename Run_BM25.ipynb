{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5664d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"metadata/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta['title_abstract'] = df_meta['title'] + ' ' + df_meta['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34217bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from __future__ import division \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(line, tokenizer=word_tokenize):\n",
    "    utf_line = line.lower()\n",
    "    return [token for token in tokenizer(utf_line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')) \n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "def extract_and_tokenize_terms(doc):\n",
    "    terms = []\n",
    "    for token in tokenize(doc):\n",
    "        if token not in stopwords:\n",
    "            if not re.search(r'\\d',token) and not re.search(r'[^A-Za-z-]', token): \n",
    "                terms.append(stemmer.stem(token.lower()))\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31da1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('corpusData.json') as f:\n",
    "#     documents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd1990",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = dict(zip(list(df_meta['cord_uid']),list(df_meta['title_abstract'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ab76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_tokenize = {k:extract_and_tokenize_terms(v) for k,v in documents.items() if type(v) == str and pd.notna(k)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "    \n",
    "inverted_index = defaultdict(set)\n",
    "for docid, terms in documents_tokenize.items():\n",
    "    for term in terms:\n",
    "        inverted_index[term].add(docid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = len(documents_tokenize)\n",
    "avg_doc_len = sum([len(doc) for doc in documents_tokenize.values()])/num_docs\n",
    "\n",
    "\n",
    "def tf_idf_score(param_k1,param_b,term,docid):  \n",
    "    \n",
    "    ft = len(inverted_index[term]) \n",
    "    term = stemmer.stem(term.lower())\n",
    "    fdt =  documents_tokenize[docid].count(term)\n",
    "    \n",
    "    inverse_doc_freq = math.log((num_docs - ft + 0.5)/(ft+0.5))\n",
    "    tf_comp = (((param_k1 + 1)*fdt)/(param_k1*((1-param_b) + param_b*(len(documents_tokenize[docid])/avg_doc_len))+fdt))\n",
    "    \n",
    "    return inverse_doc_freq * tf_comp\n",
    "\n",
    "def create_tf_idf(param_k1,param_b):\n",
    "    tf_idf = defaultdict(dict)\n",
    "    for term in set(inverted_index.keys()):\n",
    "        for docid in inverted_index[term]:\n",
    "            tf_idf[term][docid] = tf_idf_score(param_k1,param_b,term,docid)\n",
    "    return tf_idf\n",
    "\n",
    "tf_idf = create_tf_idf(1.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qtf_comp(k3,term,fqt):\n",
    "    return ((k3+1)*fqt[term])/(k3 + fqt[term]) \n",
    "\n",
    "def retr_docs(query,result_count):\n",
    "    query_terms = [stemmer.stem(term.lower()) for term in query.split() if term not in stopwords]    \n",
    "    fqt = {} \n",
    "    for term in query_terms:\n",
    "        fqt[term] = fqt.get(term,0) + 1\n",
    "        \n",
    "    scores = {}\n",
    "    \n",
    "    for word in fqt.keys():\n",
    "        for document in inverted_index[word]:\n",
    "            scores[document] = scores.get(document,0) + (tf_idf[word][document]*get_qtf_comp(0,word,fqt))\n",
    "    \n",
    "    return sorted(scores.items(),key = lambda x : x[1] , reverse=True)[:result_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74848acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('C:/Users/user/Downloads/Practicum_Test/rnd5_topics.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "run = []\n",
    "for element in root.iter('query'):\n",
    "    value = element.text\n",
    "    run = run + retr_docs(value, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8846af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(run)\n",
    "df.rename(columns = {0:'docid',1:'score'}, inplace = True)\n",
    "df['rank'] = [None]*len(df)\n",
    "df['topicid'] = [None]*len(df)\n",
    "# df['result'] = [None]*len(df)\n",
    "df['Q0'] = ['Q0']*len(df)\n",
    "df['run_tag'] = ['dcu']*len(df)\n",
    "id_=1\n",
    "rank = 1\n",
    "for i in range(len(df)):\n",
    "    df['topicid'][i] = id_\n",
    "    df['rank'][i] = rank\n",
    "    rank+=1\n",
    "    if (i+1)%1000==0:\n",
    "        id_+=1\n",
    "        rank = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2515e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[['topicid','Q0','docid','rank','score','run_tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('TA1000_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06849a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('TA1000_result.csv') \n",
    "\n",
    "df_deduplicated = df2.drop_duplicates(subset=['topicid', 'docid'])\n",
    "\n",
    "print(df_deduplicated)\n",
    "df_deduplicated.to_csv('deduplicated_table_TA_1000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bff270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
